# Week 7-M-Index Concurrency
1. Index Data Structure
2. Concurrently 하게 Access하는데 있어서
3. 그 접근을 제어하겠다. 
	→ 여기서는 그 대상이 Index

하나의 process로 구성된 메모리 영역에 대해 
one single execution flow 이었는데, 
이제 multiple threads를 생성을 시켜서 각 thread가 각자의 stack을 가지고 코드를 실행
→ 메모리 내부의 파일을 같이 볼 수 있는 환경이 된다. 
→ `multi threaded execution`

## Data 접근
1. Read
2. Write → 내가 읽고 있는데, 누가 바꿔버리면 지금 내가 읽고 있는 데이터가 올바른 데이터인지를 확신하지 못한다. 
	→ `Correctness Issue` 발생
	→ `Conflict`
	→ `Race Condition`

각 쓰레드(클라이언트)가 쿼리를 받으면 DBMS가 동작한다. 
Index를 여러개의 thread가 접근해서 자기가 원하는 value를 찾아가고자 할때, 
Index가 중간에 변경되는 경우 원하는 value가 변경되지 않게 접근을 제어해야 한다. 

`Index`에 접근하는 multithread를 제어한다고 해서
`Index Concurrency Control` 이라고 한다. 

Database에 접근하는 multiuser를 제어한다고 해서
`Database Concurrency Control` 이라고 한다. 

> [!Concurrency Control]
> DBMS uses to ensure “**correct**” results for concurrent operations on a shared object.

제어하는 대상에 따라 그 이름이 달라진다. 
수업에서는 Index Concurrency Control 에 대해 다룬다. 

## Concurrency Control
1. `Logical Correctness`
	접근하는 thread가 데이터를 볼 권한이 있는지
	그 권한을 맞게 주고 있는지
2. `Physical Correctness`
	tree, hash table, skip list, try-catch,,,등등
	데이터의 값이 아닌, 데이터의 구성(internal structure)이 변경된 상황
	cf. tree에서 데이터를 split하는 과정에서 representation에서 완결이 되지 않아. physically한 위치에 데이터가 없는 상황에 접근을 하려고 하면 physical correctness에 어긋나게 된다. 
## Latches
1. 두 접근 중 하나라도 Write권한을 가지고 접근을 할 때 Conflict가 발생한다. 
2. 두 접근이 동일한 Index에 접근을 할 때 blocking을 해서 access control을 해주어야 한다. 
access control을 위한 locking mechanism에서 필요한게 `latch`이다. 

따라서, hash table과 b+ tree에서 각각 어떻게 Concurrency Control을 하는지를 알아볼 것이다. 
## Lock vs. Latches
> database의 관점에서

- lock: database table, record, tuple을 보호하기 위해 사용되는 메커니즘을 일컫는다. 
- latches: in-memory 상에 올라와있는 shared memory를 보호하기 위해 일시적으로 사용되는 잠금 메커니즘을 `latch`라고 한다. 
![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20241022194200.png]]
Deadlock이 발생했을 때, Lock은 발견하고 해결하면 되지만, Latches는 해결할 방법이 없기 때문에 처음에 짤 때부터 잘 짜야된다. 
## Latch Modes
Conflict Operation(원인)을 잘 찾는 것이 가장 중요하다. 
Read-Read 는 데이터베이스가 직접적으로 변경되지 않기 때문에, 동시 접근을 허용한다. 

따라서, 어떤 Database든 Mode를 가지고 구현을 해놓았다. 

1. 데이터를 접근하기 이전에 특정 Mode의 latch를 잡아놓는다. 
2. 이후에 안전성에 따라 latch를 unlock할지를 결정한다. 
## Latch Implementations
1. Blocking OS Mutex(상호 배재)
```cpp
	mutex.acquire() -> latch
	{
	... -> 실행할 동작 및 보호해야할 코드(Critical Section)
	}
	mutex.release() -> unlatch
```
	only single thread만 사용이 가능하고 나머지는 CPU burning하며 기다리고 있다. 

2. Test-and-Set Spin Latch
	Critical Section의 코드를 Test를 통과한 thread만 실행할 수 있도록 허용
3. Reader-Writer Side Locks
	thread가 접근할 때마다 read/writer count & wait 값을 증가 혹은 감소 시켜서 접근을 제어
![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20241022194200-1.png]]
→ 추후에 Database Concurrency Control 부분에서 세련된 방법으로 다시 나온다. 
## Hash Table Latching
Concurrency Control은 잘할수록 속도와 직결되기 때문에, 가장 중요하다. 
Hash Table vs. Tree 

Hash Table은 Table like Structure이기 때문에, 데이터가 잘 이동하지 않는다. 그러나, Tree like Structure는 구조가 변할 확률이 높다(Split, Merge 등 구조변경이 자주 됨). 따라서, Physical Correctness를 걱정해주어야할 경우가 많아진다. 

Table based Data Structure는 `Natural parallelism` 을 가지고 있다.
1. Internal Structure가 잘 변하지 않는다. 
2. 자연스럽게 병렬적으로 처리가 되도록 구성이 되어 있다. 

따라서, hash table은 Concurrency Control 에 꽤 유리한 구조를 이미 가지고 있기 때문에, latch를 통으로 잡아버리면 `Concurrency Degree`가 1로 떨어져 버린다. 그렇기 때문에 latch를 얼마나 잡을건지를 결정할지가 중요!!
### Latch Granularity
> latch를 어느정도 잡을건지. 

#### #1. Page Latches
Latch 범위(granul)를 크게 가져감
page 단위로 Latch를 걸어서 해당 페이지에 대한 동시 접근을 막아둠. 
Concurrency Degree가 커짐. 
#### #2. Slot Latches
Latch 범위(granul)를 작게 가져가서 그만큼 Concurrency하게 사용자들이 접근할 수 있지만, 많은 양의 Latch를 사용해야 함. 
→ 현재 나온 Latch들 중에 가장 이상적이다. 

→ leaf를 작게 가져가는 것이 더 빠르고 효율적으로 데이터에 접근할 수 있다. 

## B+ Tree Concurrency Control
Concurrency Control을 해결하기 위해서는 주원인을 밝혀내는 것에 시간이 가장 많이 걸린다. 

Concurrent Access를 할 때, 
`logical correctness criteria` 도 잘 염두해두고 들여다봐야하지만, 
Structure 자체가 변화하면서 `physical Correctness criteria`의 invariant가 breaking되는 상황을 잘 살펴봐야하기에 더 체계적이다. 

`SMO(Structure Modification Ops)`에 의해 발생하는 문제가 없도록 더 주의깊게 설계해야한다. 

**pdf에 나온 예제**는 `physical correctness`를 깨는 예를 특별히 살펴본다. 

![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250304110005-1.png]]
1. 44를 지워야겠다고 결정하자마자, 41을 오른쪽으로 옮기겠다고 결정했다고 하자. 
   아직 옮기지는 않고, 코드 상으로 옮기겠다고 판단만 끝낸 순간이다. 

![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250304110005-2.png]]
2. T1이 rebalance를 시키고 나간 뒤에, 최하위 노드의 값이 아예 사라졌으니깐, 상단 노드의 pointer의 값도 최신화 시켜주었다. 
3. T2는 아까 ‘44의 key는 38과 41 사이에 있으니깐 사이의 포인터를 통해서 들어가야지’ 라는 판단 하에 H노드로 내려간다. 그러나, T1에 의해 41은 I노드로 옮겨졌다. 
> [!NOTE]
> 가정을 하는 시점과 팔로우하는 코드는 서로 다른 코드이다. 따라서, 가정이 코드를 팔로우할 때까지 유효해야한다. 
> Assumption이 코드를 실행하는 시점까지 Hold가 되어 있어야 한다. 따라서, `판단을 하는 시점`과 `Action을 하는 시점`사이에 `Rebalance가 들어가버리는 것`이 문제이다. 
> Read한 Value를 기준으로 Action을 취할 때까지 변함이 없을 것이라는 가정이 있어야한다. 

그러나, Multi-Thread 환경에서 각각의 Action은 Seperate Code로써 동작한다. 
Action의 Assumtion이 깨지게 되면, 데이터의 Invariant가 깨져버리는 것이다. 

Read를 했을 때의 Value를 토대로 만든 Assumption부터, Code가 실제로 동작할 때까지 Rebalance가 일어나지 않아야 한다!!! → 가장 중요
따라서, 그 사이의 모든 과정에 대한 protection이 이루어져야 한다. 

> [!NOTE]
> 1. node 자체를 보호하는 것도 중요하지만 (logical correctness)
> 2. 해당 node로 가는 node들의 structure(마치 라우터) 또한 보호를 해주어야 한다. (physical correctness)
>    → operation에 따라서 모든 node가 protect되어야 할 수도 있고, 일부 node만 protect가 필요할 수도 있다. 

## Latch Crabbing/Coupling
> a.k.a hand-in-hand latching

: 연쇄적으로 Node를 Read해나갈 때, Node하나의 latch를 잡은 뒤 읽고 다음 포인터로 이동해서 또 latch를 잡고 읽는 것을 반복하는 것을 의미한다. 

safe Node라는 판단은 어떻게 하느냐? 
linked list에서 옮겨갈 때, 할려고 하는 operation으로 인해 변화하는 pointer의 변화는 Route의 변화와 직결된다. 

![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250304110007.png]] 이런식으로 생긴 Linked List(1, 2, 3)가 있다고 하면, 중간 Node(2)가 Delete되는 상황이 발생하면, 첫번째 Node(1)와 중간 Node(2)의 Latch를 잡고 있어야 한다. 만약, Doubly Linked List라면 3개의 Node의 구조 변경이 모두 일어나기에 모두 Latch를 잡아야 한다. 

Linked List → 정방향의 Pointer만 있기에 1, 2만
Doubly Linked List → 쌍방향의 Pointer가 모두 있기에 1, 2, 3 전부 잡아야 한다. 

나의 현재 `Operation을 통해 발생하는 SMO의 범위를 잘 파악`하고, SMO가 일어나는 `모든 Scope의 Node`를 잡아야 한다. 
Split으로 인한 Propagation이 Root까지 갈 수 있기 때문에, 그런 최악의 상황이라면, Root부터 해당 Node까지의 모든 Latch를 잡고 있어야 한다. 그럴 필요가 없다는 판단이 서는 순간에 Release를 하게 된다. 

### Read
→ SMO를 전혀 유발하지 않기 때문에, Logical guarantee하기 위해서 Node를 2개만 잡으면 된다. 
Pointer를 통해 `판단(이전 노드에서)`하고, `직접 접근(다음 노드로의)(Action)이 완료되는 시점`까지 `양쪽 Node의 Latch`를 잡고 있는다. 완료가 되면 이전 Node의 Latch를 풀 수 있다. 
따라서, Read operation 같은 경우에는 최대로 잡고 있는 Node 수가 2개이다. 
### Write: Delete 38
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250313142327-1.png]]
20, 35를 가진 노드는 pointer가 하나씩 밖에 없네? 
그러면 Merge되면 SMO의 파급 범위가 Root까지 올 수 있겠네?
20, 35를 갖고 있는 Node를 일단 Latch를 다 잡고 있는다. 

어? 그런데, 다음 노드가 38과 44를 둘 다 가지고 있으니깐 하나를 지운다고 하더라도 위쪽 Tree의 SMO는 유발하지 않겠네?(Merge될 경우가 없으니깐) 그니깐 위에서 잡고 있던 Latch를 풀어도 되겠네? 라는 판단이 서게 된다. 
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250313142327-2.png]]
### Write: Insert 44
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250313142328.png]]
44를 Insert하기 위해 20, 35 Node를 Latch를 잡고 내려가는데, 35 Node가 비어있네? 
그러면 상위 Node까지 영향을 미칠 일이 없겠네? 
그니깐 20 Node의 Latch는 풀어도 되겠네? 라는 판단을 내린다. ![Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250416150918-2.png](IMG-20250416150918-2%206.png)
어? 그런데, 아래 38, 44 Node는 둘 다 차 있네?
그러면 일단 상위에 비어있는 35 Node도 일단은 잡고 있어야 겠다. 
![Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Lecture/Lec 12 (10.14)/IMG-20250416150918-3.png](IMG-20250416150918-3%205.png)
그런데, 더 내려가보니깐 44 Node 는 비어있네? 그러면 위에 잡고 있던 Latch를 모두 풀어도 되겠다! 
와 같은 식으로 동작한다. 

따라서, 중요한 것은 
`Delete`: `Merge를 유발`하는 Condition(다 차있는 Node를 잘 파악)
`Insert`: `Split을 유발`하는 Condition(비어있는 Node를 잘 파악)
을 파악하는 것이 중요하다!!











> [!NOTE]
> read를 할 때 가리켰던 포인터 주소를 도중에 누가 들어와서 write를 시키는 것에서 문제가 발생한다. 따라서, read를 할 때 다른 thread가 rebalancing을 못하게끔 막아야 한다. 
> 
> 결과적으로, pointer가 변경되지 않게끔 latch hold를 잘해주는 것이 중요하다. 

tree에서는 root에서부터 내가 원하는 node까지의 모든 node를 붙잡고 있어야한다. 
latch를 푸는 순간은 내가 잡고 있는 node 상위의 node가 변경되지 않을거 같으면, 위의 latch를 모두 풀 수 있다. 

==다시 공부해보기==

전체 tree의 root를 통으로 계속 잡고 있으면, 다른 쓰레드가 데이터에 계속 접근을 못하기 때문에 latency가 정말 커진다. 




