Storage와 Memory간에 속도의 차가 발생하게 된다. 

아래에 있는 데이터를 위로 올리는 데에 너무 오랜 시간이 걸린다. 
따라서, buffer manager에 자주 쓰는 데이터를 올려놓은 뒤에 빠르게 사용할 수 있게끔 만들어주는 노력이 필요하다. 
![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 7 (9.23)/IMG-20241022194159.png]]

## Buffer Pool Organization
buffer pool 의 frame도 paginated 되어 있다. 
1. 각 frame에 On-Disk File의 포인터를 넘겨준다. 
2. Buffer Pool에 어떤 page가 담겨있는지를 알려주는 `Page Table`이 필요하다. 
   `Page Table'에는 각 page의 주소 포인터를 담고 있다. 
   그리고, 변경을 관리할 수 있게 Page Table에서 자체적으로 Lock을 관리한다. ![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 7 (9.23)/IMG-20241022194159-1.png]]
### Locks vs. Latches
Latch는 주로 Mutex로 구현된다. 

## Buffer Pool Optimizations
### Multiple Buffer Pools
보통 mutax 형태의 latch로 concurrency Control을 하기 때문에, 여러개의 Buffer Pool을 설정함으로써 `Load Balancing`이 가능하게 해준다. 
`fragmentation`: Load Balancing이 안되게 되면, 용량이 큰데 실제로는 resource를 아주 조금만 사용하는 문제가 발생하는 것을 얘기한다. 
### Pre-Fetching
`Spatial한 특성이 있음` → 미리 Fetching해와. 
![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Midterm/4. Buffer Manager/IMG-20250304110005.png]]
- page0, 1을 읽으면, page2, 3를 다음으로 읽을 것을 미리 예측하고 4KB가 아니라 8KB를 요청해서 page2, 3을 미리 불러온다.
- 이는 Spatial 특성을 활용해서 Sequential 하게 불러오는 것이다. 
![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Midterm/4. Buffer Manager/IMG-20250304110005-1.png]]
- Index Scan에서도 pre-fetching을 사용할 수 있다. 
![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Midterm/4. Buffer Manager/IMG-20250304110007.png]]
### Scan Sharing
동일한 Table에 Scan을 하려고 하는 여러 쿼리가 들어오면, Buffer Pool에 걸리는 I/O Activity가 급증하게 된다. 
	ex) 방금 전에 읽은 Table을 또 읽을려고 했는데, 바로 다른 Process가 채가는 경우

**Scan Sharing**은 데이터베이스 시스템에서 **여러 쿼리가 동일한 테이블을 스캔할 때, 데이터를 중복해서 읽지 않도록** 하는 최적화 기법입니다. 즉, 한 쿼리가 테이블을 스캔 중일 때, 동일하거나 유사한 스캔이 필요한 다른 쿼리는 **이미 실행 중인 스캔에 연결**하여 중복된 읽기 작업을 방지합니다. 이는 스토리지나 연산에 필요한 시간을 절약하여 **I/O 비용을 줄이고 성능을 향상**시킬 수 있습니다.

이러한 방식은 **synchronized scans**라고도 한다. 
Piggy back의 idea를 사용해서 한 쿼리가 스캔을 시작하면 다른 쿼리들이 그 스캔을 **타고 들어가서** 필요한 데이터를 가져올 수 있다는 의미를 담고 있습니다. 즉, **다른 쿼리들이 같은 스캔을 "얹어서"** 결과를 함께 가져오는 방식입니다.
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/4. Buffer Manager/IMG-20250313142327-1.png]]
### Buffer Pool Bypass
가끔은 없는걸로 치는게 더 나을 때도 존재한다. 
- 한 번 읽고 재사용이 될 확률이 적은 데이터들
- OLAP와 같이 큰 테이블을 읽는 워크로드

> [!NOTE]
> `Load Balancing`
> load를 줄이기 위한 randomzation
> → 강조하시는 개념인듯!!!!

# Buffer Replacement Policy

## LRU Replacement Policy
`1. Dirty?`
`2. Pin Count?`
`3. Last Used?`
→ 셋 중에선 `Last Used`를 가장 중요한 Attribute로 보자
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/4. Buffer Manager/IMG-20250313142327-2.png]]
만약에, **Dirty Attribute가 Y로 표시**되어 있다면 메모리에서는 변경이 이루어졌는데, 디스크에는 아직 덮어씌어지지 않았을 수도 있다.  
따라서, Write를 Disk에 먼저 해주고, 그 다음에 제거를 진행한다. 
![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 7 (9.23)/IMG-20250304110005-1.png]]
oldest Entry를 찾기 위해서 모든 `Last Used` 배열을 linearly search해야한다. 
이는 너무 많은 용량을 차지하기 때문에 Approximate가 필요하다. 
Approximate가 필요, 너무 많은 용량 차지하기 때문에 
## LRU-C
> LRU를 Approximate했더니 잘 돌아가네?
> triumph of Approximation

Clock Algorithm 사용!
한 주기 동안 봤을 때, 한번도 Access안된 애들은 빼는 방법 사용
→ `Reference Bit` 한바퀴를 도는 동안에 1로 올라갔으면 확인 후에 다시 0으로 내린다. 

계속 row를 내려가면서 `Dirty 여부를 체크`한다. 
## Sequential Scan + LRU(least recently)
가장 적게 사용된 것을 빼버리자!
→ Cache Hits가 0이 되는 경우도 발생
## Sequential Scan + MRU(most recently)
Replacement policy를 변경해서
Cache Hit이 일어나게끔 한다.

## LRU-K
**LRU-2**를 사용하여 페이지 A, B, C가 차례로 두 번씩 참조되었다고 가정합시다.
- 페이지 A: 참조 시점 (10, 20)
- 페이지 B: 참조 시점 (15, 25)
- 페이지 C: 참조 시점 (5, 30)
이때 페이지 C는 마지막으로 참조된 시점은 최근이지만, **가장 오래된 참조 시점**이 다른 페이지들보다 오래됐기 때문에, 페이지 C가 교체될 우선순위에 있습니다.
## Approximate LRU-K
K번 참조되었는지를 간접적으로 확인한다. 
## Localization
각 쿼리가 자신의 작업에만 필요한 페이지들만 버퍼풀에 유지하고, 쿼리가 완료되면 불필요한 페이지들을 교체 대상으로 선택
### **Dirty Pages** (더티 페이지)
1. **페이지 상태에 따른 처리**:
    - **빠른 처리**: 버퍼풀에 있는 페이지가 **더티 페이지가 아닐 때**(즉, 변경된 적이 없고 디스크에 저장된 내용과 동일할 때), DBMS는 해당 페이지를 단순히 **"드롭"** 할 수 있습니다. 즉, 메모리에서 바로 제거할 수 있으므로 처리 속도가 매우 빠릅니다.
    - **느린 처리**: 반면, 페이지가 **더티 페이지**인 경우(메모리에 있는 페이지가 변경되었고 디스크의 내용과 불일치할 때), DBMS는 **변경된 데이터를 디스크에 기록해야 합니다**. 이를 통해 데이터 손실을 방지하고 변경 사항이 영구적으로 저장됩니다.
2. **트레이드오프**:
    - **빠른 페이지 교체 vs. 더티 페이지 처리**: 더티 페이지를 처리할 때는 **디스크 I/O** 작업이 필요하기 때문에 시간이 더 오래 걸릴 수 있습니다. 특히, 더티 페이지가 **다시 읽힐 가능성이 낮을 때도** 디스크에 기록해야 하기 때문에, 불필요한 쓰기 작업이 발생할 수 있습니다. 반면, 더티 페이지가 아닐 경우는 빠르게 처리할 수 있습니다.
### **Background Writing** (백그라운드 쓰기)
1. **백그라운드에서 주기적인 쓰기**:
    - DBMS는 **주기적으로 페이지 테이블을 확인**하여 **더티 페이지를 디스크에 기록**할 수 있습니다. 이 과정은 **백그라운드에서 수행**되기 때문에 메인 작업 흐름에 큰 영향을 미치지 않고, 데이터가 안전하게 디스크에 기록될 수 있도록 도와줍니다.
2. **안전한 쓰기 후 페이지 처리**:
    - 더티 페이지가 안전하게 디스크에 기록되면, DBMS는 해당 페이지를 **삭제**하거나 **더티 플래그를 초기화**할 수 있습니다. 이를 통해 더티 페이지가 아닌 일반 페이지로 변환하여 다음 교체 작업 시 빠르게 처리할 수 있습니다.
3. **주의사항**:
    - **로그 기록 순서**: 더티 페이지를 디스크에 기록할 때, **해당 페이지의 로그 기록이 먼저 기록되었는지**를 확인해야 합니다. 로그 기록이 완료되지 않은 상태에서 더티 페이지가 기록되면 **데이터 무결성**에 문제가 발생할 수 있기 때문입니다. 즉, **로그 순서**를 유지하는 것이 중요합니다.

