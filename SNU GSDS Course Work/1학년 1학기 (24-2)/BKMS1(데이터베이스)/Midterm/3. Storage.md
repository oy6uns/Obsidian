> database를 관리할 수 있는 software를 어떻게 만들지를 다룬다. 

## OverView: Representation
1. Record를 어떻게 표현할까?
2. 파일의 페이지에 Record를 어떻게 배치할까?
![[IMG-20241022194636.png]]
> [!NOTE]
> Storage의 핵심
> Physical Independence는 지켜야할 중요한 성질
> `Indirection` → 가장 중요!!
> 
> → Pagination, Slotted Page 등등이 다 그런 이유에서 나온 것들

## Disk Based Architecture
- primary 저장장소가 Non-volatile storage라고 가정하고 저장된다. 
- DBMS의 Component들이 non-volatile & volatile storage간의 데이터 이동을 관리할 수 있어야 한다. 
  
`저장 시에 고려할 것`
1. 어떻게 잘 찾지에 대한 문제도 같이 따라온다. 
2. 누구를 먼저 불러와야 되지?

`Volatile`
	CPU Register: 비싼만큼 빠르다
	- Random Access
	- Byte-Addressable
`Non-Volatile`
	SSD, HDD, Network Storage: 싼만큼 느리다. 
	- Sequential Access
	- Block-Addressable

Non-Volatile DRAM도 고려는 되고 있지만, 가격과 성능의 절충안을 아직 잘 찾지 못했다. 

## Access Times
![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 4 (9.11)/IMG-20241022194159.png]]
## SEQUENTIAL VS. RANDOM ACCESS
- `volatile 저장소`에서는 **read/write하는데에 overhead가 크다**. 따라서, 랜덤하게 접근해서 하나하나 읽는 것 보다 `sequential access`로 데이터를 연속적으로 읽는 것이 비교적 빠르다. 
  → 따라서 DBMS의 알고리즘은 데이터가 최대한 연속된 block에 저장되도록 하여 **임의 페이지에 대한 Write 횟수를 줄이려고 노력**해야한다. 
- `non-volatile 저장소`에서는 데이터를 읽기 위해 **물리적으로 이동할 필요가 없으므로**, 즉각적으로 원하는 데이터에 접근할 수 있다. 따라서, Random(비순차적) 데이터 접근에도 빠른 응답 속도를 유지할 수 있다. 
## System Design Goals
- Disk(non-volitile)에 대한 **read/write는 비용**이 많이 들기에 신중하게 설계해야한다. 
- Disk에서 Random Access는 일반적으로 Sequential Access보다 훨씬 느리기 때문에 DBMS는 **Sequential Access를 최대화**하려고 해야한다. 
- DBMS는 **사용가능한 Memory 양을 초과하는 데이터베이스**를 관리하도록 설계된다. 
  → 일반적으로 Memory의 용량이 Disk의 용량보다 작다. 
## Disk-Oriented DBMS
어떤 데이터에 접근은 많이 하는지를 파악하고, 다음에 동일한 데이터에 다시 접근하려고 할 때, 어떻게 하면 빠르게 처리할 수 있을지에 대해서 고민한다. (Buffer Manager)

## 왜 그런데 이런 일을 OS가 아니라 DB가 해야돼요?
- `Memory Mapping(mmap)`
	파일의 내용을 프로그램의 메모리 공간에 직접 매핑하는 기능이다. 
	OS가 파일의 데이터를 직접 메모리로 올리고, DBMS는 이를 그대로 사용하여 파일을 읽고 쓸 수 있다! 
	운영체제가 파일의 페이지를 메모리로 관리하면 **DBMS는 직접 메모리 관리에 신경 쓰지 않아**도 된다. **그런데 왜 그렇게 안할까?**

Ans: 운영체제는 `General-purpose`로 설계되어 있기에 `데이터의 sementic한 정보`를 모르기 때문이에요. 

네? 좀더 자세히 설명해주세요

**OS는 General Purpose로 설계되어 있다**
- 즉, 운영체제는 특정한 프로그램이나, 애플리케이션에 맞춰 설계된 것이 아니라, 다양한 프로그램과 작업을 처리할 수 있도록 설계되어있다. 
- 예를 들어, 운영체제는 데이터베이스, 웹 브라우저, 게임, 문서 편집기 등 **모든 종류의 프로그램**이 실행될 수 있는 환경을 제공합니다.. 각 프로그램이 어떻게 작동하는지 세부적으로는 알지 못하고, 그저 **일반적인 자원 관리**(메모리, CPU, 파일 시스템 등)를 제공하는 역할을 합니다.
**따라서, 데이터의 Sementic한 정보는 알지 못한다.** 
- **Semantic**은 **의미**를 말해요. 즉, 데이터의 **의미나 구조**에 대해 운영체제는 알지 못한다는 뜻입니다.
- 예를 들어, **데이터베이스**는 데이터가 어떤 테이블에 저장되어 있고, 어떤 열이 고객 이름이고, 어떤 열이 나이인지를 알고 있어요. 하지만 운영체제는 이 정보를 알지 못해요. 운영체제는 그저 "파일 안에 **어떤 값들이 저장되어 있다**"는 사실만 알고, **그 데이터가 무슨 의미를 가지는지**는 모릅니다.

운영체제는 데이터베이스나 특정 애플리케이션의 요구에 맞춘 세부적인 데이터 처리 방식을 제공하지 않고, 파일 읽기/쓰기나 메모리 할당 같은 일반적인 자원 관리만을 담당해요. 

따라서, OS에게 일을 맡기는 것이 비효율적이고, 몇몇 문제가 발생한다. 
1. `Transaction Safety`
	운영체제는 메모리에서 **변경된 페이지(Dirty Pages)를 언제든지 디스크로 Flush**할 수 있어요. 그러나 DBMS에서는 데이터의 일관성(1강에서 말한 내용!)을 유지하기 위해 transaction이 완료되기 전까지 특정 데이터를 디스크에 쓰지 않도록 해야하는 경우가 많습니다. 운영체제가 이를 제어하지 않기 때문에, transaction시 데이터 무결성(data integrity)에 문제가 발생할 수 있습니다. 
2. `I/O Stalls(입출력 지연 문제)`
	운영체제가 메모리를 관리하기 때문에, DBMS는 어떤 페이지가 메모리에 올라와 있는지를 알 수 없어요. 따라서, 메모리에 없는 페이지에 접근 시에 페이지 폴트(page fault)가 발생하여 해당 페이지를 디스크에서 읽어와야 됩니다. 
	다중 쓰레드 환경에서 **쓰레드과 중단**되고 **I/O 지연이 발생**하는 것은 성능에 큰 영향을 미칠 수 있어요. 
3. `Error Handling`
	페이지에 대한 접근이 잘못되면 **SIGBUS**와 같은 오류가 발생하는데, 이는 DBMS가 직접관리하지 않는 부분에서 발생하므로, 적절한 오류 처리가 매우 복잡하고 어려워질 수 있습니다. 
4. `Performance Issues`
	컴퓨터가 프로그램을 실행할 때, 프로그램이 사용하는 **가상 메모리 주소**를 **실제 메모리 주소**로 변환해야 해요. 이 변환 과정은 페이지 테이블을 통해 이루어지는데, 이 **페이지 테이블**을 매번 참조하면 시간이 많이 걸리기 때문에 **TLB**라는 캐시가 이 변환정보를 미리 저장해둡니다. 
	**TLB**는 메모리 주소 변환을 빠르게 하기 위한 **작은 노트**처럼 생각할 수 있어요. 우리가 자주 찾는 주소나 정보를 적어놓고, 바로바로 빠르게 참조할 수 있죠. 
	그런데 만약 이 노트에 적힌 내용이 자주 바뀌거나 새로 써야 할 내용이 많아지면, 기존 내용을 지우고 새로 적는 시간이 자주 발생하게 돼요. 이렇게 되면 노트를 활용하는 속도가 느려지겠죠? 이게 바로 **TLB Shootdown** 입니다. 
	**TLB가 자주 무효화되면** 메모리 접근할 때마다 새로운 변환 정보를 다시 불러와야 하므로, **메모리 접근 속도가 느려지고 성능이 저하**될거에요. 

아직 (**MonetDB, LMDB, LevelDB**)와 같은 몇몇 DBMS는 운영체제의 메모리 매핑을 완전히 사용하기도 하고, **MongoDB**나 **SQLite**도 운영체제의 메모리 관리 기능을 부분적으로 활용하기는 합니다. 
그러나 DBMS가 스스로 메모리와 데이터를 관리하게 하는 게 효율성과 성능 측면에서 더 나은 모습을 보입니다. 

> [!+ 지식!]
>클라우드 환경으로 전환되면서, 기업들이 물리적인 서버나 디스크를 직접 관리하지 않고 **클라우드 제공 업체**가 제공하는 **가상화된 인프라**를 사용하게 되었습니다. 이 가상화된 환경에서는 **하드웨어 장치**에 직접 접근하는 것이 아니라, **클라우드 서비스의 추상화된 스토리지 레이어**를 통해 데이터를 관리하게 됩니다.
>- 예를 들어, Amazon S3와 같은 **클라우드 스토리지 서비스**는 사용자가 물리적인 디스크나 장치의 세부 사항을 알 필요 없이 데이터를 저장하고 관리할 수 있게 해줍니다.
>- 클라우드 환경에서는 사용자들이 **물리적인 장치**를 직접 제어하는 대신, **클라우드 인프라**가 이러한 역할을 대신해줍니다.
>
>그러나 **클라우드 서비스**가 점점 더 정교해지면서, 클라우드 사용자가 자신의 요구에 맞게 **저수준의 디스크 제어 기능**을 다시 확보하는 방향으로 변하고 있습니다. 즉, 클라우드 제공자가 제공하는 높은 수준의 추상화 외에도, **더 세밀한 디스크 제어**(예: 성능 최적화, 스토리지 구조 최적화)를 위해 **Raw Device 수준의 접근**을 허용하거나 지원하는 기능들이 등장하고 있는 상황입니다.
>- 예를 들어, **Amazon EC2**에서는 **EBS(Elastic Block Store)**라는 가상 디스크를 사용할 수 있고, 사용자는 여전히 이 가상 디스크를 **디스크 장치**처럼 직접 제어할 수 있습니다.
>- **컨테이너**나 **서버리스** 환경에서도, 데이터 저장소를 더 직접적으로 제어하려는 요구가 증가하고 있습니다. 예를 들어, **데이터베이스 성능을 극대화**하거나 **트랜잭션 처리 속도를 높이기 위해** 특정 클라우드 인프라에서 **디스크 I/O 작업**을 더 세밀하게 제어할 필요가 있을 수 있습니다.
# Database Pages
> Physical Independence를 만족시키는 첫번째 개념
> `page-oriented storage scheme`

기존에는 **디스크의 블록을 직접 제어**하는 **raw block storage** 방식으로 데이터를 저장했지만, **신규 DBMS는 더 이상 이를 사용하지 않고 운영체제의 파일 시스템**을 이용해 데이터를 관리합니다.

> [! 파일 시스템이란?]
> - **파일 시스템**은 운영체제가 **파일과 디렉토리를 관리**하는 방식입니다. 즉, 디스크에 저장된 데이터를 **어떤 구조로 저장할지**를 정의하는 계층이에요.
> - 파일 시스템은 **파일을 생성, 삭제, 읽기, 쓰기** 등의 기본 작업을 제공합니다. 데이터베이스, 텍스트 파일, 이미지 등 **모든 종류의 데이터**가 파일 시스템을 통해 관리됩니다.
## Storage Manager
> a.k.a. Disk Space Manager
> 데이터베이스 파일을 유지 관리 하는 구성요소입니다. 쉽게 말해, 데이터베이스가 디스크에 저장하는 **모든 데이터를 저장하고 추적하며, 파일 단위로 데이터를 관리**합니다. 

### Read/Write의 스케줄링 (Spatial & Temporal Locality)
일부 Storage Manager는 데이터를 읽고 쓰는 작업을 자체적으로 스케줄링합니다. 
즉, 어떤 데이터에 먼저 접근하고, 어떤 데이터를 나중에 처리할지를 관리하는 기능을 가지고 있습니다. 
#### Spatial & Temporal Locality
- `Spatial Locality(공간 지역성)`: 데이터가 **서로 가까운 위치에 저장**되어 있으면, 그 데이터를 한꺼번에 읽거나 쓸 때 효율이 높아집니다. 연속된 페이지를 한 번에 읽어오는 것이 빠르기 때문이다. 
- `Temporal Locality(시간 지역성)`: **최근에 사용된 데이터**가 다시 사용될 가능성이 높다는 원리를 바탕으로, 자주 접근하는 데이터를 더 빠르게 읽고 쓰는 방식을 사용합니다.
### 페이지(page) 단위로 파일을 관리
데이터베이스의 파일은 `page`라는 단위로 조직된다.  
- 데이터 읽기/쓰기 추적: Storage Manager은 어떤 페이지에 데이터가 **읽히거나 쓰였는지를 추적**합니다. 이를 통해 데이터 접근 패턴을 이해하고, 더 효율적인 입출력을 수행할 수 있습니다. 
- 사용 가능한 공간 추적: Storage Manager은 **어느 페이지가 사용 가능하고, 어느 페이지가 꽉 차 있는지**도 추적합니다. 이를 통해 새로운 데이터를 어디에 저장할지를 결정합니다. 
### Replication(복제)은 Storage Manager의 주요 기능이 아니다!
Storage Manager는 단순히 데이터를 **페이지 단위로 관리**하는 역할을 하며, **복제**와 같은 더 높은 수준의 데이터 무결성 보장 기능을 별도의 시스템에서 관리됩니다. 

## Storage Manage의 Physical Independence
Storage의 정보가 옮겨다니더라도 `Disk Space Manager`가 알고 있는 정보가 바뀌어서는 안된다 → `Physical Independence`

그니깐 추상화를 하자!!
단위를? 위에서 말했듯이 `page` 로 

책임은 항상 Disk Space Manager가 진다. 
→ 윗단에서 page를 찾을 때 우선적으로 `page ID`부터 찾는다. 
   그러면 `Disk Space Manager`가 해당 `page ID`의 정보를 윗단으로 보내준다. 
위쪽에서는 physical Disk의 데이터가 어디에 어떻게 위치해 있는지 아무런 관심이 없다. 그저 해당 page ID에 대한 정보를 똑 보내주기만 하면 되는거다. 해당 page ID에 대한 정보를 찾고, `indirection mapping table을 참고해서 resolving`하는 것은 전적으로 `Disk Space Manager`가 책임져야 한다. 

## 그래서 Page가 뭐야?
- 페이지는 **고정 크기의 데이터 블록**을 의미한다. 
  페이지는 아래와 같은 데이터들을 포함한다. 
	- **Tuples(튜플)**: 테이블의 한 행(row), 즉 실제 데이터입니다.
	- **Meta-data(메타데이터)**: 데이터에 대한 정보입니다. 예를 들어, 데이터가 언제 생성되었는지, 어떤 형식인지 등의 정보를 말합니다.
	- **Indexes(인덱스)**: 데이터 검색을 빠르게 할 수 있게 도와주는 구조입니다.
	- **Log records(로그 기록)**: 트랜잭션 처리 중의 변경 사항을 기록해 두는 로그입니다.
### Page의 고유 식별자: Unique Identifier
- 각 페이지는 **고유한 식별자(ID)** 를 부여 받습니다. 이 식별자는 페이지를 찾고 관리하는데 사용됩니다. 
- **Indirection Layer(간접 계층)**: 데이터베이스는 **pageID**를 사용하여 **간접 계층**을 통해 실제 물리적 위치로 매핑합니다. 즉, 페이지가 물리적으로 어디에 저장되어 있는지에 대해 간접적인 경로를 통해 접근할 수 있습니다. 
### 기본 DB Page Size
각 데이터베이스 시스템은 기본적으로 다른 페이지 크기를 사용합니다. 
- **4KB 페이지 크기**를 사용하는 데이터베이스: SQLite, Oracle, IBM DB2, RocksDB 등
- **8KB 페이지 크기**를 사용하는 데이터베이스: Microsoft SQL Server, PostgreSQL 등
- **16KB 페이지 크기**를 사용하는 데이터베이스: MySQL 

페이지 크기는 데이터 베이스 성능에 큰 영향을 미칠 수 있습니다. 
- 예를 들어, **작은 페이지 크기**를 사용하면 데이터를 더 세밀하게 관리할 수 있지만, **I/O 작업이 많아**질 수 있습니다. 반대로, **큰 페이지 크기**를 사용하면 **I/O 효율성이 높아**지지만, **메모리 사용량이 증가**할 수 있습니다. 
따라서 각 데이터베이스 시스템은 자신의 사용 목적에 맞는 최적의 페이지 크기를 선택하여 효율을 극대화하는 방안을 택해야합니다!
## Page Storage Architecture
disk의 paging된 파일들을 관리하기 위한 방법들은 다음과 같이 있다. 
![[Img/SNU GSDS/BKMS1(데이터베이스)/Lecture/Lec 4 (9.11)/IMG-20241022194159-1.png]]
`tuple`들로 구성된 `page들의 unordered collection`을 `heap file`이라 부른다. 

![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 4 (9.11)/IMG-20250304110005-1.png]]
`Disk Space Manager`가 `page Id`를 입력 받았을 때, `offset`을 계산해서 페이지의 시작 위치를 찾고 몇 바이트의 정보를 위로 보내줄지를 결정하게 됩니다!

## 2가지 Heap File 구조
### 1. Page Directory
![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 4 (9.11)/IMG-20250304110005-2.png]]
**특별한 페이지(디렉토리 페이지)를 두어** 데이터가 저장된 페이지의 위치를 추적하는 방법입니다. 
- 데이터 페이지가 **동기화 상태**를 유지하도록 관리해야합니다. 즉, 데이터 페이지에 변경이 있을 때, 디렉터리 페이지에도 그 정보를 반영해야 합니다. 
- 디렉토리 페이지에는
  1. **각 페이지에 남은 빈 슬롯의 수**를 기록하거나
  2. **빈 페이지나 사용가능한 페이지 목록**을 기록하여 나중에 데이터를 어디에 추가할 수 있을지
  를 추적합니다. 
### 2. Linked List
파일의 **처음에 헤더 페이지를 유지**하며, 두 개의 포인터를 저장하는 방식입니다. 
- 첫 번째 포인터는 **빈 페이지 List**의 head를 가리키고, 
- 두 번째 포인터는 **데이터가 저장된 페이지 List**의 head를 가리킵니다. 
그러나, Linked List는 페이지 간의 이동에 I/O가 자주 발생하기 때문에 잘 쓰이지 않는다. 

`따라서, heap file은 보통 directory 구조로 쓰입니다!!` 

> [!NOTE]
> 다시 한번 말하지만, Disk Space Manager에서 이루어지는 모든 일들은 Page ID 하나로만 이루어진다. 

그러면, `page ID` 로 찾아온 데이터는 어떤걸까? `Record` 의 `Column Data`가 데이터의 format일 것이다. 

그러면, `Column Data가 저장되어 있는 Page의 각 Tuple` 들을 어떤식으로 `Page에 저장`시켜야될까?

# Tuple-Oriented Storage
> table의 tuple을 단위로 저장된 storage이다. 

문제점이 몇가지 있다!
- **튜플을 삭제 시**: 삭제된 튜플은 페이지에서 비어있게 되며, 그 공간을 다시 사용하기 어렵게 된다. 
  - `internal fragmentation`: 튜플 내부의 column 공간이 비어있음(NULL로 잡혀있음)에도, 다른 튜플의 데이터가 들어오지 못하는 상황
  - `external fragmentation`: 외부적으로 봤을 때, 공간의 총합은 충분하지만 내부적으로 파편화가 나서 외부의 튜플이 들어오지 못하는 현상
    → `compaction` 작업을 통해 문제를 해결할 수 있다.  
	 그러나 page organization의 시간이 아주 오래 걸리기 때문에 최대한 미루는 것이 좋다. 
- **변동 길이의 속성(Variable-Length Attribute)**: 튜플 안의 속성이 **고정된 길이**가 아니고 **변동적인 길이**를 가지면 튜플의 크기가 매번 달라지기 때문에 관리가 복잡해집니다. 
## Slotted Pages

![[Img/Img/SNU GSDS/1학년 1학기/BKMS1(데이터베이스)/Lecture/Lec 4 (9.11)/IMG-20250304110007.png]]
- **슬롯 배열(Slot Array)**: 페이지 안에 **슬롯 배열**이 있고, 각 슬롯은 해당 튜플이 페이지 안에서 시작되는 **위치 오프셋**을 가리킵니다. 이 배열을 통해 튜플의 위치를 효율적으로 추적할 수 있습니다.
- **페이지 헤더(Header)**: 페이지 상단에 **헤더**가 있으며, 헤더는 다음과 같은 정보를 추적합니다:
    1. **사용된 슬롯의 개수**: 페이지 안에서 현재 사용 중인 슬롯의 수를 나타냅니다.
    2. **마지막으로 사용된 슬롯의 시작 위치 오프셋**: 마지막으로 삽입된 튜플의 위치를 기록하여 다음 튜플이 저장될 위치를 관리합니다.

튜플은 **위에서부터 저장**되게끔하고, Slot Array는 **뒤에서부터 채워**지게끔해서 최대한 **Page의 공간을 효율적으로 사용**할 수 있게 됩니다. 

### 자 그럼 결론적으로, 
In page에서 움직이는 경우, Slot Array의 # 이 처리한다. 
page 단위에서 움직이는 경우, Page ID가 처리한다. 

 `Page ID`, `Slot Array의 #` 의 2가지 정보를 통해 Memory와 Storage 간의 `Physical Independece` 를 유지할 수 있다!!!

그러면, table의 tuple은 어떤 식으로 저장될까?
## Tuple Layout
### Fixed Length
문제가 없다~ 그냥 이쁘게 저장해주면 된다. 
![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250313142327.png]]
- `CREATE TABLE` 문을 통해 테이블을 정의할 때 다섯가지 속성을 아래와 같이 정의했을 때
    - `a`: `INT` 형식의 기본 키
    - `b`: `INT` 형식의 NOT NULL 속성
    - `c`: `INT` 형식
    - `d`: `DOUBLE` 형식
    - `e`: `FLOAT` 형식
   → 이 테이블이 생성되면, 각 튜플은 정의된 순서에 따라 `a, b, c, d, e`의 순서대로 저장됩니다.
### VARIABLE LENGTH
여기서 문제가 발생한다. ![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250313142327-1.png]]

→ **VARCHAR형은 길이가 제각각**이기 때문이다. 
1. 그러면 CHAR(#)으로 변환해서 padding을 줘보자!
	- wasted space의 발생 가능성이 생긴다
	- 길이를 초과하는 String이 들어올 수 있다. 
2. comma로 seperate 해볼까?
   ![[Img/Img/SNU GSDS/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250313142328.png]]
	- 특정 field에 access할 때, scan이 필요하게 된다. 
	- 텍스트 내부에 comma(,)를 포함하게 되도 문제가 생긴다
4. 아 그러면, VARCHAR로 그대로 두되, 앞에 offset을 명시해주자!
   ![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150918-2.png]]
	- String이 길면, 아직 access에 오버헤드가 발생한다. 
5. **tuple header**를 따로 빼서 포인터를 적어주자!!
   ![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150918-3.png]]해결!!!
### 그럼 Tuple Header에는 어떤 정보를 적나!!
- **Tuple Header의 내용**:
    - **Visibility Info(가시성 정보)**: **동시성 제어(concurrency control)** 를 위해 사용됩니다. 여러 트랜잭션이 동일한 데이터에 접근할 때, 데이터가 어느 트랜잭션에 의해 변경되었는지, 그리고 다른 트랜잭션에서 볼 수 있는지에 대한 정보를 저장합니다.
    - **Bit Map for NULL Values(널 값 비트맵)**: 튜플에 **NULL 값**이 있는 속성이 있을 경우, 이 비트맵이 해당 속성에 대해 **NULL 여부**를 표시합니다. 즉, 어떤 속성이 NULL인지 빠르게 확인할 수 있도록 비트맵을 사용합니다.
      ex) 데이터가 아래와 같을 때, `Bit Map: 10101`
		- `student_id`: 3 (값이 존재함)
		- `name`: NULL (값이 없음 → 0)
		- `age`: 22 (값이 존재함)
		- `major`: NULL (값이 없음 → 0)
		- `gpa`: 3.5 (값이 존재함)
- 중요한 점은, **튜플 헤더에 스키마에 대한 메타데이터는 저장하지 않는다는 것**입니다.
  스키마에 대한 정보는 테이블의 구조를 정의하는 별도의 메타데이터에서 관리되며, 각 튜플에 그 정보를 저장할 필요는 없다!! 윗선에서 해결해야하는건 아랫선까지 넘어오지 않게 한다!

## 결론
Database는 page에 의해 organized되어 있다. 
- 페이지를 추적
- 페이지를 저장
- 튜플을 저장
하기 위한 다양한 방법들이 존재한다!

## Page Storage Architecture의 단점
### #1. Fragmentation
**튜플을 삭제 시**: 삭제된 튜플은 페이지에서 비어있게 되며, 그 공간을 다시 사용하기 어렵게 된다. 
  - `internal fragmentation`: 튜플 내부의 column 공간이 비어있음(NULL로 잡혀있음)에도, 다른 튜플의 데이터가 들어오지 못하는 상황
  - `external fragmentation`: 외부적으로 봤을 때, 공간의 총합은 충분하지만 내부적으로 파편화가 나서 외부의 튜플이 들어오지 못하는 현상
    → `compaction` 작업을 통해 문제를 해결할 수 있다.  
	 그러나 page organization의 시간이 아주 오래 걸리기 때문에 최대한 미루는 것이 좋다. 
### #2. Useless Disk I/O
하나의 tuple을 위해서 그 tuple이 담긴 페이지 전체를 DBMS가 fetch해와야하므로, Useless Disk I/O가 발생한다. 
- `amplication` = physical size(전체 물리적 크기) / net size(필요한 크기
	- `WAF`: write시에 발생하는 amplication
	- `RAF`: read시에 발생하는 amplication
### #3. Random Disk I/O (중요)
1. multiple tuples를 update하다보면
2. 각 tuple이 seperate page들에 나눠져서 존재하게 된다. 
3. Read/Write 시에 여러번의 random disk I/O가 발생하게 된다. 

→ 임의의 주소공간에 가서 읽고/쓰고 하는 작업(`Inplace Update`)을 하지 않고, 저장 자체를 Sequential 하게 하고 싶다!(`Out-of-place Update`) 

→ 그러면 Random Disk I/O를 해결할 수 있지 않을까?

# Log-Structured Storage
- Deffered Compaction
  값을 합치고 동기화하는 작업을 뒤로 미루어서 동작
- SST: Sorted String Table
	여러개의 SST를 읽어서 하나의 큰 SST를 만들고, 맨 앞에 SST의 index를 가지고 있게끔 한다. 
	Level별로 SST를 저장하고, 다 차면 아래 Level로 내려간다. 
	맨 위에 존재하는 Root SST를 Memory layer에 존재한다고 해서 `MemTable`이라고 부른다. 
### 단점
- Read가 느리다. 
	단계별로 찾아야 되고, Merge가 이루어져야 정확한 Search가 가능한데 Merge 할 때마다 I/O가 발생한다. 
### 장점
- 대신에 Write가 좋다. `Insert` only workload에서 굉장히 성능이 좋다. 
- 내가 써야할만큼만 사용하면 되기에 Useless Disk I/O 문제도 해결할 수 있다. 
## Log-Structured Storage의 단계
1. `Memtable`에 값들을 집어 넣는다. 
2. `Memtable`이 가득 차면 새로운 `New Memtable`을 만든다. 
3. `New Memtable`에 Write가 계속 쌓이고, 기존의 가득 찬 `Memtable`은 아래 Level로 Flush시킨다.  
4. `Compaction`
   - Leveling: 각 레벨의 SST(Sorted String Tables) 파일을 더 낮은 레벨의 큰 SST 파일로 병합하는 방식이다. 레벨이 높아질수록 SST 파일의 개수는 줄어들고 크기는 커진다. 
     **장점**: 레벨이 높아질수록 데이터는 더욱 정렬되므로, 데이터 검색 시 더 **적은 파일만 조회하면 된다**. **읽기 성능이 좋아**진다. 
     **단점**: **병합 작업이 자주 발생할 수 있어 쓰기 성능**에 영향을 줄 수 있다. 
   - Tiering: 같은 레벨의 SST 파일들이 일정 수 이상 쌓이면 병합하지 않고 단순히 다음 레벨로 이동시키는 방식이다. 병합은 필요한 시점에만 수행된다. 
     **장점**: SST 파일을 바로 병합하지 않기 때문에 **쓰기 성능이 높다**. 
     **단점**: 레벨에 여러 파일이 존재하므로, **읽기 성능이 떨어**진다. 
  - Universal: 전체 Level에서 Compaction을 진행한다. 
     그러나 Lock을 너무 많이 잡아 먹기 때문에 거의 사용하지 않는다. 

→ 떨어지는 Read 성능을 보완하기 위해, `bloom filter` hash table을 활용하여 데이터 접근을 돕는다. 

# Index-Organized Storage
guide post로 Index가 Routing으로 사용되고, 
tree의 leaf node에 tuple들이 저장되어 있다. 
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150919.png]]
위의 그림은 leaf node에 **page, tuple이 직접 담겨** 있는 형태의 Storage이고(MySQL)

추가적으로 아래에 하나의 node를 더 구성해서 **leaf node의 포인터**가 **heap storage를 가리키고 있는 구조**들도 자주 사용된다. (Postgres)

## Word-Aligned Tuples
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150919-1.png]]
- 위와 같은 상황에서, zipc가 두 개의 64-bit Word에 겹쳐서 있기 때문에, Read Amplication Factor(RAF)가 2가 된다. (128/64, 실제로는 64만 읽으면 되지만 128을 불러와야함)
- 이런 상황에서 useless I/O가 발생하게 되는 것이다. 
- 따라서, Padding을 넣거나 Reordering을 통해 효과적으로 tuple 데이터를 구성해야한다. 
## System Catalogs
Information_schema Catalog를 사용해서 database의 information을 retrieval할 수 있다. 

# Database Workload
> workload에 따라 tuple에 접근해서 사용하는 목적이 다를 것이다. 
> → Net Data가 다를 것이다. 

## OLTP: Online Transaction Processing
실행되는 쿼리 자체는 데이터베이스 내부에서 정말 적은 부분에 영향을 끼치는 간단한 쿼리들이지만 그 쿼리의 수 자체가 굉장히 많은 형식의 작업에 유용 Simple queries that read/update a small amount of data ex) 온라인 쇼핑몰의 장바구니 기능

## OLAP: Online Analytical Processing

많은 양의 데이터를 불러와서 aggregates하는 query가 많을 때 유용 쓰기 연산이 거의 일어나지 않고 읽기 연산이 대부분을 이룸 ex) 온라인 쇼핑몰에서 최근 한달간 가장 많이 구매된 품목 5개를 정렬(Analysis)

## 5-1.3. HTAP: Hybrid Transaction + Analytical Processing

# Storage Models

> 디스크와 메모리에서 물리적으로 튜플을 어떻게 정렬할지에 대한 모델 모든 DB가 튜플만을 취급한다고 가정하고 설명 진행

### #1. N-ary Storage Model(NSM)
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150919-2.png]]
- 하나의 row가 추가될 때마다 DB Page의 Slot Array에 각 row가 하나씩 추가된다.
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150920.png]]
- OLTP 와 같이 row 하나를 가져오는 간단한 쿼리문은 효율적이다. → 하나의 page만 search하고, 하나의 row만 query하면 되기에
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150920-1.png]]
- 그러나, OLAP의 여러 개의 row를 가져오게 되면 불필요한 column까지 같이 query된다. → 원하는 값들을 모두 가져오기 위해 모든 페이지를 조사해야하고, 필요하지 않은 데이터까지 가져와야 하는 문제가 발생한다.
### #2. Decomposition Storage Model(DSM)
> 테이블의 하나의 속성(attribute)을 연속적으로 저장하는 방식
![[Img/Img/SNU GSDS Course Work/1학년 1학기 (24-2)/BKMS1(데이터베이스)/Midterm/3. Storage/IMG-20250416150920-2.png]]

**장점**
- 빠른 Inserts, Updates, and Deletes
- entire tupe을 필요로 하는 OLTP의 query 시에 효율적

**단점**
- 대규모 portion을 scanning 시에 속성의 일부분을 원한다면 매우 비효율적
---
그러면 **Attiribute별로 정렬된 데이**터가 **어느 index에 속하는지**를 어떻게 Identify할까?

2가지 방법 존재한다.

1. Offsets: 각 index의 데이터별로 고정길이의 offset을 설정하여 구분이 가능하게끔 한다.
``` python
A: 1, 2, 3, 4
B: 5, 6, 7, 8
C: 9, 10, 11, 12
D: 13, 14, 15, 16
```
2. Embedded Ids: 각 데이터 별로 index를 Id로 하여 값을 분류할 수 있게끔 한다.
```python
A: (0, 1), (1, 2), (2, 3), (3, 4)
B: (0, 5), (1, 6), (2, 7), (3, 8)
C: (0, 9), (1, 10), (2, 11), (3, 12)
D: (0, 13), (1, 14), (2, 15), (3, 16)
```
→ 이렇게 하면 가변 길이 데이터도 각 값에 해당하는 튜플 ID를 통해 데이터의 위치를 쉽게 추적할 수 있다. 

### #3. PAX: Partition Attributes
NSM과 DSM의 hybrid version storage model이다. 
묶음 단위는 column 별로 묶고, 일정 개수의 row로 잘라서 저장하는 방식

> [!NOTE]
> Storage Model이 각 Workload에 도움되는 방향으로 구성되어 발전해왔구나를 알 수 있다. 

# Database Compression
### Goal
1. 공간상의 이득이 크게끔
2. 나중에 사용될 때 데이터의 손실 없이 복구가 가능해야 한다. 

## Compression Granularity
> 압축시키는 단위를 어느정도로 잡고 볼 것이냐?
1. Block-level
2. Tuple-level
3. Attribute-level
4. `Column-level` → 주된 관심사

## Columnar Compression
### #1. Run-length Encoding
![[IMG-20250416150920-3.png]]
- 동일한 값이 연속으로 나와있는 경우 등장한 위치를 명시해주면, 훨씬 간단하게 요약본으로 만들 수 있다.   ![[IMG-20250416150920-4.png]]
- Sorted Data인 경우 훨씬 더 간단하게 나타낼 수 있다. 
### #2. Bit-Packing Encoding
![[IMG-20250416150921.png]]
필요없는 bit 값들은 제거하고, 나머지 비트로만 표현한다. 
### #3. Bitmap Encoding
![[IMG-20250416150922.png]]
### #4. Delta Encoding ![[IMG-20250416150922-1.png]]
값의 연속된 차이를 combine하여 압축한다. 
### #5. Incremental Encoding
![[IMG-20250416150922-2.png]]
하나의 값이 유독 변수형에 비해 클 때, offset과 value를 따로 빼서 저장한다. 
### #6. Dictonary Encoding
위에 Embedded Ids에서 사용했던 것 처럼, key-value dictionary를 만든 후에,
기존의 테이블의 value 대신에 정수 key값으로 대체한다. 

















> [!System?]
> 시스템은 Pros/Cons가 항상 존재한다. 
> 이전의 디자인들이 갖고 있는 문제점을 해결하기 위한 디자인들이 많이 나온다. 
> 따라서, Weakness의 원인 분석을 해야, 새로운 디자인을 내놓을 수 있다. 
> → CS에서 디자인을 바라볼 때 `Design Rationale(이론적 해석)` 을 잘 이해해야 한다. 

> [!중요 내용]
>` Indirection principle `
> pysical data independence가 깨지는 모든 상황에서 아주 general 하게 들어맞는 design principle이다!
